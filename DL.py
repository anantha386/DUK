# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1brYK-DFgM-14tz8a7y1gn543AxjOJvB1
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

data = pd.read_csv(r'/content/sample_data/COVIDSenti-A.csv') #read file
data

data.dtypes

data.count()

import re
import string
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

def preprocess_text(tweet):
    tweet = tweet.translate(str.maketrans('', '', string.punctuation))  # remove punctuation
    # convert to lowercase
    tweet = tweet.lower()
    # remove stop words
    stop_words = set(stopwords.words('english'))
    tokens = tweet.split()
    tweet = [token for token in tokens if token not in stop_words]
    tweet = ' '.join(tweet)
    # apply stemming or lemmatization
    stemmer = PorterStemmer()
    tweet = stemmer.stem(tweet)
    
    return tweet

import nltk
nltk.download ('stopwords')

data1 = pd.read_csv(r'/content/sample_data/COVIDSenti-A.csv')

# Preprocess the text data
data1['tweet'] = data1['tweet'].apply(preprocess_text)

df1.head()

X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2)

vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

model = SVC(kernel='linear', C=1)
model.fit(X_train, y_train)

v=vectorizer.transform([new_tweet])

v.shape

model.predict(ve)

print(preprocess_text)

